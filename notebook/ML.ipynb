{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2679f704",
   "metadata": {},
   "source": [
    "# Análisis Comparativo de Modelos Ensemble para Predicción de Consumo Energético\n",
    " \n",
    "Este notebook implementa y compara diferentes algoritmos de ensemble learning para la predicción del consumo energético, incluyendo Random Forest, Gradient Boosting y XGBoost. El objetivo es identificar el mejor modelo y método de optimización de hiperparámetros.\n",
    " \n",
    "## Estructura del Análisis\n",
    "1. Carga y Preparación de Datos: Dataset preprocesado con adición de ruido realista\n",
    "2. Modelos Base: Implementación de tres algoritmos ensemble principales\n",
    "3. Optimización de Hiperparámetros: Comparación de GridSearch, RandomSearch y BayesianSearch\n",
    "4. Evaluación Comparativa: Análisis de rendimiento entre todos los enfoques\n",
    "5. Visualizaciones: Gráficos diagnósticos y comparativos\n",
    "6. Persistencia: Guardado del mejor modelo para producción\n",
    " \n",
    "### Configuración del Entorno\n",
    " \n",
    "Librerías clave para ensemble learning:\n",
    "- sklearn.ensemble: Random Forest y Gradient Boosting clásicos\n",
    "- xgboost: Implementación optimizada de Gradient Boosting\n",
    "- skopt: Optimización bayesiana de hiperparámetros\n",
    " \n",
    "¿Por qué modelos ensemble?\n",
    "Los métodos ensemble combinan múltiples modelos para obtener mejor rendimiento que cualquier modelo individual:\n",
    "- Reducción de varianza: Promedio de múltiples predicciones reduce ruido\n",
    "- Reducción de sesgo: Diferentes modelos capturan diferentes patrones\n",
    "- Mayor robustez: Menos sensibles a outliers y ruido en datos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62ce554d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import joblib\n",
    "import warnings\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configurar estilo de gráficos\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette('husl')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71f81cd4",
   "metadata": {},
   "source": [
    "### Carga de Datasets Preprocesados\n",
    " \n",
    "Utilizamos los mismos datasets que en el análisis SVR para asegurar comparabilidad directa entre diferentes enfoques de modelado. Los datos ya han pasado por:\n",
    "- Codificación de variables categóricas (one-hot encoding)\n",
    "- Limpieza y tratamiento de valores faltantes\n",
    "- Estructuración consistente entre train/test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b128ab82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. CARGAR Y PREPARAR LOS DATOS\n",
    "train_df = pd.read_csv('../data/processed/energy_data_processed.csv')\n",
    "test_df = pd.read_csv('../data/processed/energy_data_processed_test.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6bbc4aa",
   "metadata": {},
   "source": [
    "### Separación de Variables y Adición de Variabilidad Realista\n",
    " \n",
    "Separación estándar:\n",
    "- X_train, X_test: Matrices de características para entrenamiento y prueba\n",
    "- y_train, y_test: Vectores de variable objetivo\n",
    " \n",
    "Adición de ruido gaussiano:\n",
    "Se mantiene la misma estrategia del notebook SVR para consistencia:\n",
    "- noise_factor = 0.1: 10% del rango total de la variable objetivo\n",
    "- Distribución normal: Ruido más realista que ruido uniforme\n",
    "- Mismo seed: Garantiza reproducibilidad entre experimentos\n",
    " \n",
    "Justificación del ruido:\n",
    "- Datos perfectos son irreales: En la práctica siempre hay variabilidad no explicada\n",
    "- Evita overfitting artificial: Modelos demasiado perfectos no generalizan bien\n",
    "- Simula incertidumbre: Refleja errores de medición y factores no observados\n",
    " \n",
    "Monitoreo de la transformación:\n",
    "- Verificamos que el rango y varianza del ruido sean apropiados\n",
    "- Mantenemos las propiedades estadísticas básicas de los datos originales\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "162aa5ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma del dataset de entrenamiento: (1000, 9)\n",
      "Forma del dataset de prueba: (100, 9)\n",
      "Variable objetivo: Energy Consumption\n",
      "\n",
      "Varianza de y_train con ruido: 1086917.99596434\n",
      "Rango de y_train con ruido: [1442.89, 6860.07]\n",
      "Varianza de y_test con ruido: 973255.7143404601\n",
      "Rango de y_test con ruido: [1875.14, 6906.85]\n"
     ]
    }
   ],
   "source": [
    "# 2. SEPARAR CARACTERÍSTICAS Y VARIABLE OBJETIVO\n",
    "y_train = train_df['Energy Consumption']\n",
    "X_train = train_df.drop('Energy Consumption', axis=1)\n",
    "y_test = test_df['Energy Consumption']\n",
    "X_test = test_df.drop('Energy Consumption', axis=1)\n",
    "\n",
    "# Verificar tamaños\n",
    "print(f'Forma del dataset de entrenamiento: {X_train.shape}')\n",
    "print(f'Forma del dataset de prueba: {X_test.shape}')\n",
    "print(f'Variable objetivo: {y_train.name}')\n",
    "\n",
    "# Añadir ruido aleatorio para simular datos más realistas\n",
    "np.random.seed(42)  # Para reproducibilidad\n",
    "noise_factor = 0.1  # 10% del rango de y_train\n",
    "y_train_range = y_train.max() - y_train.min()\n",
    "y_train_noisy = y_train + np.random.normal(0, noise_factor * y_train_range, size=y_train.shape)\n",
    "y_test_noisy = y_test + np.random.normal(0, noise_factor * y_train_range, size=y_test.shape)\n",
    "print(\"\\nVarianza de y_train con ruido:\", y_train_noisy.var())\n",
    "print(\"Rango de y_train con ruido: [{:.2f}, {:.2f}]\".format(y_train_noisy.min(), y_train_noisy.max()))\n",
    "print(\"Varianza de y_test con ruido:\", y_test_noisy.var())\n",
    "print(\"Rango de y_test con ruido: [{:.2f}, {:.2f}]\".format(y_test_noisy.min(), y_test_noisy.max()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872c634b",
   "metadata": {},
   "source": [
    "### Escalado de Características para Modelos Ensemble\n",
    " \n",
    "¿Es necesario escalar para árboles de decisión?\n",
    "- Random Forest/Gradient Boosting: No requieren escalado (son invariantes a transformaciones monótonas)\n",
    "- XGBoost: Tampoco requiere escalado estrictamente\n",
    " \n",
    "¿Por qué escalamos entonces?\n",
    "1. Consistencia experimental: Mantener las mismas condiciones que en SVR\n",
    "2. Comparabilidad: Eliminamos el escalado como variable confundidora\n",
    "3. Futuros experimentos: Si queremos probar modelos híbridos o ensemble con algoritmos sensibles al escalado\n",
    "4. Regularización: Algunos parámetros de regularización pueden funcionar mejor con datos escalados\n",
    " \n",
    "Proceso de escalado:\n",
    "- fit_transform en entrenamiento: Calcula media y desviación estándar\n",
    "- transform en prueba: Aplica la misma transformación sin recalcular estadísticas\n",
    "- Prevención de data leakage: No usamos información de test para el escalado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0fb19c50",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. ESCALADO DE CARACTERÍSTICAS (opcional para árboles, pero útil para consistencia)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "299e78a0",
   "metadata": {},
   "source": [
    "### Implementación de Modelos Ensemble Base\n",
    " \n",
    "Configuración de cada algoritmo:\n",
    " \n",
    "1. Random Forest:\n",
    "- n_estimators=100: 100 árboles para balance entre rendimiento y velocidad\n",
    "- max_depth=10: Limita profundidad para controlar overfitting\n",
    "- min_samples_split=5: Mínimo 5 muestras para dividir un nodo\n",
    "- min_samples_leaf=2: Mínimo 2 muestras en hojas terminales\n",
    "- Estrategia: Bagging (bootstrap + promedio) para reducir varianza\n",
    " \n",
    "2. Gradient Boosting:\n",
    "- n_estimators=100: 100 iteraciones de boosting\n",
    "- max_depth=5: Árboles más simples (stumps mejorados)\n",
    "- Mismos parámetros de regularización que Random Forest\n",
    "- Estrategia: Boosting secuencial que corrige errores previos\n",
    " \n",
    "3. XGBoost:\n",
    "- n_estimators=50: Menos iteraciones (XGBoost es más eficiente)\n",
    "- max_depth=3: Árboles muy simples para evitar overfitting\n",
    "- reg_alpha=1.0, reg_lambda=2.0: Regularización L1 y L2\n",
    "- gamma=0.5: Penalización por complejidad del árbol\n",
    "- Estrategia: Gradient boosting optimizado con regularización avanzada\n",
    " \n",
    "Diferencias clave entre algoritmos:\n",
    "- Random Forest: Paralelo, robusto, menos prone a overfitting\n",
    "- Gradient Boosting: Secuencial, más expressivo, puede overfittear\n",
    "- XGBoost: Gradient boosting optimizado, mejor regularización, más rápido\n",
    " \n",
    "Evaluación inmediata:\n",
    "Calculamos métricas base para establecer benchmark antes de optimización"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0011545d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Random Forest BÁSICO ===\n",
      "MSE: 232561.3204\n",
      "RMSE: 482.2461\n",
      "R²: 0.7586\n",
      "MAE: 388.5226\n",
      "\n",
      "=== Gradient Boosting BÁSICO ===\n",
      "MSE: 252435.1228\n",
      "RMSE: 502.4292\n",
      "R²: 0.7380\n",
      "MAE: 397.0668\n",
      "\n",
      "=== XGBoost BÁSICO ===\n",
      "MSE: 265444.2876\n",
      "RMSE: 515.2129\n",
      "R²: 0.7245\n",
      "MAE: 412.0864\n"
     ]
    }
   ],
   "source": [
    "# 4. MODELOS ENSEMBLE\n",
    "models = {\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42, max_depth=10, min_samples_split=5, min_samples_leaf=2),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, random_state=42, max_depth=5, min_samples_split=5, min_samples_leaf=2),\n",
    "    'XGBoost': XGBRegressor(n_estimators=50, random_state=42, eval_metric='rmse', max_depth=3, reg_alpha=1.0, reg_lambda=2.0, gamma=0.5)\n",
    "}\n",
    "\n",
    "# Entrenar y evaluar modelos básicos\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    print(f'\\n=== {name} BÁSICO ===')\n",
    "    model.fit(X_train_scaled, y_train_noisy)  # Usar y_train_noisy\n",
    "    y_pred_test = model.predict(X_test_scaled)\n",
    "    \n",
    "    mse = mean_squared_error(y_test_noisy, y_pred_test)  # Usar y_test_noisy\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test_noisy, y_pred_test)\n",
    "    mae = mean_absolute_error(y_test_noisy, y_pred_test)\n",
    "    \n",
    "    results[name] = {'MSE': mse, 'RMSE': rmse, 'R²': r2, 'MAE': mae}\n",
    "    print(f\"MSE: {mse:.4f}\")\n",
    "    print(f\"RMSE: {rmse:.4f}\")\n",
    "    print(f\"R²: {r2:.4f}\")\n",
    "    print(f\"MAE: {mae:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b8bb198",
   "metadata": {},
   "source": [
    "### Análisis Diagnóstico Preliminar\n",
    " \n",
    "Análisis de correlaciones:\n",
    "- Identifica qué características tienen mayor relación lineal con la variable objetivo\n",
    "- Ordenamiento descendente muestra las características más predictivas\n",
    "- Interpretación: Valores |r| > 0.5 son correlaciones moderadas-fuertes\n",
    " \n",
    "Validación cruzada de XGBoost:\n",
    "- ¿Por qué solo XGBoost?: Es típicamente el algoritmo de mayor rendimiento\n",
    "- 5-fold CV: Proporciona estimación robusta del rendimiento esperado\n",
    "- Scoring='r2': Métrica de varianza explicada, fácil de interpretar\n",
    "- Intervalos de confianza: ±2 desviaciones estándar (aprox. 95% confianza)\n",
    " \n",
    "Propósito del diagnóstico:\n",
    "- Baseline establecido: Rendimiento antes de optimización\n",
    "- Identificación de características: Cuáles son más importantes\n",
    "- Estimación de estabilidad: Qué tan consistente es el modelo\n",
    "\n",
    "Uso de datos con ruido:\n",
    "- Todas las evaluaciones usan y_train_noisy y y_test_noisy\n",
    "- Mantiene consistencia con la estrategia de realismo de datos\n",
    "- Permite comparación directa con el notebook SVR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "aa982d4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DIAGNÓSTICO ADICIONAL ===\n",
      "\n",
      "Correlaciones entre características y 'Energy Consumption' (con ruido):\n",
      "Square Footage               0.694921\n",
      "Building Type_Industrial     0.369221\n",
      "Number of Occupants          0.305407\n",
      "Appliances Used              0.283204\n",
      "Day of Week_Weekday          0.018533\n",
      "Average Temperature         -0.014925\n",
      "Day of Week_Weekend         -0.018533\n",
      "Building Type_Commercial    -0.030466\n",
      "Building Type_Residential   -0.330685\n",
      "dtype: float64\n",
      "\n",
      "Validación cruzada (5-fold) para XGBoost - R²: 0.7505 (+/- 0.0595)\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== DIAGNÓSTICO ADICIONAL ===\")\n",
    "\n",
    "# Correlaciones entre características y variable objetivo\n",
    "correlations = X_train.corrwith(y_train_noisy)  # Usar y_train_noisy\n",
    "print(\"\\nCorrelaciones entre características y 'Energy Consumption' (con ruido):\")\n",
    "print(correlations.sort_values(ascending=False))\n",
    "\n",
    "# Validación cruzada para XGBoost básico\n",
    "cv_scores = cross_val_score(models['XGBoost'], X_train_scaled, y_train_noisy, cv=5, scoring='r2')  # Usar y_train_noisy\n",
    "print(f\"\\nValidación cruzada (5-fold) para XGBoost - R²: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66f7aa2c",
   "metadata": {},
   "source": [
    "### Comparación Exhaustiva de Métodos de Optimización de Hiperparámetros\n",
    " \n",
    "Estrategia experimental:\n",
    "Se implementan tres enfoques diferentes para optimizar XGBoost y determinar cuál es más efectivo para este problema específico.\n",
    " \n",
    "1. GridSearchCV - Búsqueda Exhaustiva:\n",
    "- Ventajas: Garantiza encontrar el óptimo dentro del espacio definido\n",
    "- Limitaciones: Computacionalmente costoso, crece exponencialmente\n",
    "- Espacio reducido: 2×2×2×2×2×2×2 = 128 combinaciones\n",
    "- Uso típico: Espacios pequeños, cuando hay tiempo suficiente\n",
    " \n",
    "2. RandomizedSearchCV - Búsqueda Aleatoria:\n",
    "- Ventajas: Más eficiente, explora mejor espacios de alta dimensionalidad\n",
    "- n_iter=50: Evalúa 50 combinaciones aleatorias\n",
    "- Espacio completo: Usa todas las opciones del param_grid\n",
    "- Uso típico: Exploración inicial, espacios grandes\n",
    " \n",
    "3. BayesSearchCV - Optimización Bayesiana:\n",
    "- Ventajas: Más inteligente, usa información de evaluaciones previas\n",
    "- Espacios continuos: Real() permite explorar valores intermedios\n",
    "- Prior='log-uniform': Para learning_rate, explora escalas logarítmicas\n",
    "- Uso típico: Problemas complejos, presupuesto limitado de evaluaciones\n",
    " \n",
    "Definición de espacios de búsqueda:\n",
    "\n",
    "Parámetros clave de XGBoost:\n",
    "- n_estimators: Número de árboles (más = mejor ajuste, más overfitting)\n",
    "- max_depth: Profundidad máxima (más = más complejo, más overfitting)\n",
    "- learning_rate: Tasa de aprendizaje (menor = más conservador, necesita más árboles)\n",
    "- subsample: Fracción de muestras por árbol (< 1.0 = regularización)\n",
    "- colsample_bytree: Fracción de características por árbol (regularización)\n",
    "- reg_alpha: Regularización L1 (sparsity, selección de características)\n",
    "- reg_lambda: Regularización L2 (suavidad, previene overfitting)\n",
    "- gamma: Penalización mínima para división (más = más conservador)\n",
    " \n",
    "Estrategia de evaluación:\n",
    "- 5-fold CV: Balance entre confiabilidad y costo computacional\n",
    "- neg_mean_squared_error: Optimiza directamente la métrica objetivo\n",
    "- n_jobs=-1: Paralelización para acelerar búsqueda\n",
    " \n",
    "Selección automática del mejor método:\n",
    "- Compara MSE en conjunto de prueba\n",
    "- Selecciona automáticamente el modelo con menor error\n",
    "- Proporciona trazabilidad completa del proceso de selección\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3d1e865f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- GridSearchCV ---\n",
      "Fitting 5 folds for each of 128 candidates, totalling 640 fits\n",
      "Mejores parámetros (GridSearchCV): {'colsample_bytree': 0.8, 'learning_rate': 0.1, 'max_depth': 3, 'n_estimators': 100, 'reg_alpha': 0.0, 'reg_lambda': 1.0, 'subsample': 0.8}\n",
      "Mejor MSE CV (GridSearchCV): 243796.0891\n",
      "\n",
      "--- RandomizedSearchCV ---\n",
      "Fitting 5 folds for each of 50 candidates, totalling 250 fits\n",
      "Mejores parámetros (RandomizedSearchCV): {'subsample': 0.6, 'reg_lambda': 1.0, 'reg_alpha': 0.0, 'n_estimators': 50, 'max_depth': 3, 'learning_rate': 0.1, 'gamma': 0.3, 'colsample_bytree': 0.6}\n",
      "Mejor MSE CV (RandomizedSearchCV): 249594.2863\n",
      "\n",
      "--- BayesSearchCV ---\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Fitting 5 folds for each of 1 candidates, totalling 5 fits\n",
      "Mejores parámetros (BayesSearchCV): OrderedDict({'colsample_bytree': 0.6, 'gamma': 0.5, 'learning_rate': 0.10023856637823951, 'max_depth': 3, 'n_estimators': 122, 'reg_alpha': 1.0, 'reg_lambda': 0.9773104393514005, 'subsample': 0.6})\n",
      "Mejor MSE CV (BayesSearchCV): 245527.5342\n",
      "\n",
      "=== COMPARACIÓN DE MÉTODOS DE OPTIMIZACIÓN ===\n",
      "\n",
      "GridSearchCV (Prueba):\n",
      "MSE: 238829.9856\n",
      "RMSE: 488.7023\n",
      "R²: 0.7521\n",
      "MAE: 393.0759\n",
      "\n",
      "RandomizedSearchCV (Prueba):\n",
      "MSE: 242187.9053\n",
      "RMSE: 492.1259\n",
      "R²: 0.7486\n",
      "MAE: 390.9323\n",
      "\n",
      "BayesSearchCV (Prueba):\n",
      "MSE: 256503.1255\n",
      "RMSE: 506.4614\n",
      "R²: 0.7338\n",
      "MAE: 404.6343\n",
      "\n",
      "Mejor método: GridSearchCV (MSE: 238829.9856)\n"
     ]
    }
   ],
   "source": [
    "# 5. OPTIMIZACIÓN CON BAYESIAN SEARCH PARA XGBoost (ejemplo, puedes extender a otros)\n",
    "from sklearn.model_selection import GridSearchCV, RandomizedSearchCV\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "\n",
    "# Definir espacio de hiperparámetros común\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, 8],\n",
    "    'learning_rate': [0.01, 0.1, 0.3],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    'reg_alpha': [0.0, 0.5, 1.0],\n",
    "    'reg_lambda': [0.0, 1.0, 2.0],\n",
    "    'gamma': [0.0, 0.3, 0.5]\n",
    "}\n",
    "\n",
    "# 1. GridSearchCV\n",
    "print(\"\\n--- GridSearchCV ---\")\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=XGBRegressor(random_state=42, eval_metric='rmse'),\n",
    "    param_grid={\n",
    "        'n_estimators': [50, 100],\n",
    "        'max_depth': [3, 5],\n",
    "        'learning_rate': [0.1, 0.3],\n",
    "        'subsample': [0.8, 1.0],\n",
    "        'colsample_bytree': [0.8, 1.0],\n",
    "        'reg_alpha': [0.0, 1.0],\n",
    "        'reg_lambda': [1.0, 2.0]\n",
    "    },\n",
    "    cv=5,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "grid_search.fit(X_train_scaled, y_train_noisy)  # Usar y_train_noisy\n",
    "grid_best = grid_search.best_estimator_\n",
    "grid_score = -grid_search.best_score_\n",
    "print(f\"Mejores parámetros (GridSearchCV): {grid_search.best_params_}\")\n",
    "print(f\"Mejor MSE CV (GridSearchCV): {grid_score:.4f}\")\n",
    "\n",
    "# 2. RandomizedSearchCV\n",
    "print(\"\\n--- RandomizedSearchCV ---\")\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=XGBRegressor(random_state=42, eval_metric='rmse'),\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=50,\n",
    "    cv=5,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    random_state=42\n",
    ")\n",
    "random_search.fit(X_train_scaled, y_train_noisy)  # Usar y_train_noisy\n",
    "random_best = random_search.best_estimator_\n",
    "random_score = -random_search.best_score_\n",
    "print(f\"Mejores parámetros (RandomizedSearchCV): {random_search.best_params_}\")\n",
    "print(f\"Mejor MSE CV (RandomizedSearchCV): {random_score:.4f}\")\n",
    "\n",
    "# 3. BayesSearchCV\n",
    "print(\"\\n--- BayesSearchCV ---\")\n",
    "bayes_search = BayesSearchCV(\n",
    "    estimator=XGBRegressor(random_state=42, eval_metric='rmse'),\n",
    "    search_spaces={\n",
    "        'n_estimators': Integer(50, 200),\n",
    "        'max_depth': Integer(3, 8),\n",
    "        'learning_rate': Real(0.01, 0.3, prior='log-uniform'),\n",
    "        'subsample': Real(0.6, 1.0),\n",
    "        'colsample_bytree': Real(0.6, 1.0),\n",
    "        'reg_alpha': Real(0.0, 1.0),\n",
    "        'reg_lambda': Real(0.0, 2.0),\n",
    "        'gamma': Real(0.0, 0.5)\n",
    "    },\n",
    "    n_iter=50,\n",
    "    cv=5,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    random_state=42\n",
    ")\n",
    "bayes_search.fit(X_train_scaled, y_train_noisy)  # Usar y_train_noisy y todo el conjunto de entrenamiento\n",
    "bayes_best = bayes_search.best_estimator_\n",
    "bayes_score = -bayes_search.best_score_\n",
    "print(f\"Mejores parámetros (BayesSearchCV): {bayes_search.best_params_}\")\n",
    "print(f\"Mejor MSE CV (BayesSearchCV): {bayes_score:.4f}\")\n",
    "\n",
    "# No reentrenar con early stopping debido a incompatibilidad; usar bayes_best directamente\n",
    "\n",
    "# Comparar resultados\n",
    "print(\"\\n=== COMPARACIÓN DE MÉTODOS DE OPTIMIZACIÓN ===\")\n",
    "opt_results = {}\n",
    "for name, model in [('GridSearchCV', grid_best), ('RandomizedSearchCV', random_best), ('BayesSearchCV', bayes_best)]:\n",
    "    y_pred_test = model.predict(X_test_scaled)\n",
    "    mse = mean_squared_error(y_test_noisy, y_pred_test)  # Usar y_test_noisy\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test_noisy, y_pred_test)\n",
    "    mae = mean_absolute_error(y_test_noisy, y_pred_test)\n",
    "    opt_results[name] = {'MSE': mse, 'RMSE': rmse, 'R²': r2, 'MAE': mae}\n",
    "    print(f\"\\n{name} (Prueba):\")\n",
    "    print(f\"MSE: {mse:.4f}\")\n",
    "    print(f\"RMSE: {rmse:.4f}\")\n",
    "    print(f\"R²: {r2:.4f}\")\n",
    "    print(f\"MAE: {mae:.4f}\")\n",
    "\n",
    "# Seleccionar el mejor modelo\n",
    "best_method = min(opt_results, key=lambda x: opt_results[x]['MSE'])\n",
    "ensemble_optimized = {'GridSearchCV': grid_best, 'RandomizedSearchCV': random_best, 'BayesSearchCV': bayes_best}[best_method]\n",
    "print(f\"\\nMejor método: {best_method} (MSE: {opt_results[best_method]['MSE']:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86892f50",
   "metadata": {},
   "source": [
    "### Evaluación Completa del Modelo Ensemble Optimizado\n",
    " \n",
    "Análisis del mejor modelo seleccionado:\n",
    "El modelo ensemble_optimized corresponde al algoritmo que obtuvo el menor MSE entre los tres métodos de optimización probados.\n",
    " \n",
    "Evaluación en ambos conjuntos:\n",
    " \n",
    "Conjunto de entrenamiento:\n",
    "- Propósito: Verificar capacidad de ajuste del modelo\n",
    "- Interpretación: Qué tan bien \"recuerda\" los datos de entrenamiento\n",
    "- Señal de alerta: Si es demasiado perfecto (R² ≈ 1), posible overfitting\n",
    " \n",
    "Conjunto de prueba:\n",
    "- Más importante: Mide capacidad real de generalización\n",
    "- Interpretación: Rendimiento esperado en datos nuevos\n",
    "- Métrica crítica: Esta es la que realmente importa para producción\n",
    " \n",
    "Detección de overfitting:\n",
    "- Gap train-test pequeño: Modelo bien balanceado\n",
    "- Gap train-test grande: Posible overfitting\n",
    "- Test mejor que train: Posible underfitting (raro) o casualidad estadística\n",
    " \n",
    "Validación cruzada adicional:\n",
    "- ¿Por qué otra CV?: Confirmación independiente del rendimiento\n",
    "- Datos originales: Usa y_train sin ruido para comparación\n",
    "- Intervalos de confianza: Proporciona rango de rendimiento esperado\n",
    " \n",
    "Métricas complementarias:\n",
    "- MSE: Penaliza errores grandes, útil para optimización\n",
    "- RMSE: Mismas unidades que la variable objetivo, interpretable\n",
    "- R²: Porcentaje de varianza explicada, fácil de comunicar\n",
    "- MAE: Robusto a outliers, error promedio típico\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b03ac1a4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== MODELO OPTIMIZADO (ENTRENAMIENTO) ===\n",
      "MSE: 152717.0443\n",
      "RMSE: 390.7903\n",
      "R²: 0.8594\n",
      "MAE: 312.1552\n",
      "\n",
      "=== MODELO OPTIMIZADO (PRUEBA) ===\n",
      "MSE: 238829.9856\n",
      "RMSE: 488.7023\n",
      "R²: 0.7521\n",
      "MAE: 393.0759\n",
      "\n",
      "CV RMSE: 80.5791 (+/- 33.7801)\n"
     ]
    }
   ],
   "source": [
    "# 6. MODELO OPTIMIZADO (usamos XGBoost optimizado como ejemplo principal)\n",
    "y_pred_train_opt = ensemble_optimized.predict(X_train_scaled)\n",
    "y_pred_test_opt = ensemble_optimized.predict(X_test_scaled)\n",
    "\n",
    "# Métricas para entrenamiento\n",
    "mse_train_opt = mean_squared_error(y_train_noisy, y_pred_train_opt)  # Usar y_train_noisy\n",
    "rmse_train_opt = np.sqrt(mse_train_opt)\n",
    "r2_train_opt = r2_score(y_train_noisy, y_pred_train_opt)\n",
    "mae_train_opt = mean_absolute_error(y_train_noisy, y_pred_train_opt)\n",
    "\n",
    "# Métricas para prueba\n",
    "mse_test_opt = mean_squared_error(y_test_noisy, y_pred_test_opt)  # Usar y_test_noisy\n",
    "rmse_test_opt = np.sqrt(mse_test_opt)\n",
    "r2_test_opt = r2_score(y_test_noisy, y_pred_test_opt)\n",
    "mae_test_opt = mean_absolute_error(y_test_noisy, y_pred_test_opt)\n",
    "\n",
    "print(f'\\n=== MODELO OPTIMIZADO (ENTRENAMIENTO) ===')\n",
    "print(f'MSE: {mse_train_opt:.4f}')\n",
    "print(f'RMSE: {rmse_train_opt:.4f}')\n",
    "print(f'R²: {r2_train_opt:.4f}')\n",
    "print(f'MAE: {mae_train_opt:.4f}')\n",
    "\n",
    "print(f'\\n=== MODELO OPTIMIZADO (PRUEBA) ===')\n",
    "print(f'MSE: {mse_test_opt:.4f}')\n",
    "print(f'RMSE: {rmse_test_opt:.4f}')\n",
    "print(f'R²: {r2_test_opt:.4f}')\n",
    "print(f'MAE: {mae_test_opt:.4f}')\n",
    "\n",
    "# Validación cruzada\n",
    "cv_scores = cross_val_score(ensemble_optimized, X_train_scaled, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "print(f'\\nCV RMSE: {np.sqrt(-cv_scores.mean()):.4f} (+/- {np.sqrt(cv_scores.std() * 2):.4f})')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5be7aeba",
   "metadata": {},
   "source": [
    "### Persistencia de Predicciones para Análisis Detallado\n",
    " \n",
    "Estructura de archivos generados:\n",
    " \n",
    "Columnas incluidas:\n",
    "- Valores Reales: Variable objetivo con ruido (y_train_noisy, y_test_noisy)\n",
    "- Predicciones: Salida del modelo ensemble optimizado\n",
    "- Diferencia: Error residual (real - predicho)\n",
    " \n",
    "Utilidades de estos archivos:\n",
    " \n",
    "Análisis post-hoc:\n",
    "- Identificación de outliers: Casos con errores muy grandes\n",
    "- Análisis de patrones: ¿En qué rangos el modelo falla más?\n",
    "- Distribución de errores: ¿Son normalmente distribuidos?\n",
    " \n",
    "Comparación entre modelos:\n",
    "- Consistencia: Comparar con predicciones de SVR\n",
    "- Benchmarking: Usar como baseline para futuros modelos\n",
    "- Ensemble de modelos: Combinar predicciones de diferentes enfoques\n",
    " \n",
    "Validación de negocio:\n",
    "- Casos críticos: Identificar predicciones problemáticas\n",
    "- Intervalos de confianza: Estimar incertidumbre de predicciones\n",
    "- Análisis de sensibilidad: ¿Qué características afectan más las diferencias?\n",
    "\n",
    "Uso de datos con ruido:\n",
    "- Mantiene consistencia con la estrategia experimental\n",
    "- Permite análisis comparativo directo con otros notebooks\n",
    "- Refleja incertidumbre realista en los datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c3762c74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicciones de entrenamiento guardadas en '../data/results/ensemble_predictions_train.csv'\n",
      "Predicciones de prueba guardadas en '../data/results/ensemble_predictions_test.csv'\n"
     ]
    }
   ],
   "source": [
    "# 7. GUARDAR RESULTADOS EN CSV\n",
    "train_results = pd.DataFrame({\n",
    "    'Valores Reales': y_train_noisy,  # Usar y_train_noisy\n",
    "    'Predicciones': y_pred_train_opt,\n",
    "    'Diferencia': y_train_noisy - y_pred_train_opt\n",
    "})\n",
    "train_results.to_csv('../data/results/ensemble_predictions_train.csv', index=False)\n",
    "print(\"\\nPredicciones de entrenamiento guardadas en '../data/results/ensemble_predictions_train.csv'\")\n",
    "\n",
    "test_results = pd.DataFrame({\n",
    "    'Valores Reales': y_test_noisy,  # Usar y_test_noisy\n",
    "    'Predicciones': y_pred_test_opt,\n",
    "    'Diferencia': y_test_noisy - y_pred_test_opt\n",
    "})\n",
    "test_results.to_csv('../data/results/ensemble_predictions_test.csv', index=False)\n",
    "print(\"Predicciones de prueba guardadas en '../data/results/ensemble_predictions_test.csv'\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d101bdc6",
   "metadata": {},
   "source": [
    "### Panel Completo de Visualizaciones Diagnósticas\n",
    " \n",
    "Estrategia de visualización en dos paneles:\n",
    " \n",
    "PANEL 1 - Conjunto de Prueba (2×2):\n",
    "El más crítico porque evalúa la capacidad de generalización real\n",
    " \n",
    "Gráfico Superior Izquierda - Predicciones vs Valores Reales:\n",
    "- Línea diagonal roja: Referencia de predicción perfecta (y = x)\n",
    "- Dispersión de puntos: Indica variabilidad de errores\n",
    "- Concentración en diagonal: Señal de buenas predicciones\n",
    "- Patrones sistemáticos: Podrían indicar bias del modelo\n",
    " \n",
    "Gráfico Superior Derecha - Análisis de Residuos:\n",
    "- Línea horizontal en y=0: Referencia de error cero\n",
    "- Distribución aleatoria: Indicador de modelo bien especificado\n",
    "- Patrones o tendencias: Señales de problemas (heterocedasticidad, no linealidad)\n",
    "- Outliers extremos: Casos que el modelo predice mal\n",
    " \n",
    "Gráficos Inferiores - Comparación de Modelos:\n",
    "- MSE (Izquierda): Comparación de errores absolutos\n",
    "- R² (Derecha): Comparación de capacidad explicativa\n",
    "- 6 modelos totales: 3 básicos + 3 métodos de optimización\n",
    "- Rotación de etiquetas: Evita solapamiento de nombres\n",
    " \n",
    "PANEL 2 - Conjunto de Entrenamiento (1×2):\n",
    " Complementa el análisis para detectar overfitting\n",
    " \n",
    "Interpretación conjunta Train vs Test:\n",
    "- Similaridad: Modelo bien balanceado\n",
    "- Train perfecto, Test imperfecto: Overfitting\n",
    "- Ambos imperfectos pero similares: Underfitting controlado\n",
    " \n",
    "Detalles técnicos:\n",
    "- alpha=0.6: Transparencia para ver densidad de puntos\n",
    "- dpi=300: Alta resolución para publicación\n",
    "- bbox_inches='tight': Elimina espacios innecesarios\n",
    "- plt.close(): Libera memoria después de guardar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3dfa775d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Gráfico de prueba guardado en: ../data/figures/ensemble_comparative_analysis_test.png\n",
      "📊 Gráfico de entrenamiento guardado en: ../data/figures/ensemble_comparative_analysis_train.png\n"
     ]
    }
   ],
   "source": [
    "# 8. VISUALIZACIONES\n",
    "output_dir = \"../data/figures/\"\n",
    "\n",
    "# Visualizaciones para el conjunto de prueba\n",
    "fig_test, axes_test = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "axes_test[0,0].scatter(y_test_noisy, y_pred_test_opt, alpha=0.6)  # Usar y_test_noisy\n",
    "axes_test[0,0].plot([y_test_noisy.min(), y_test_noisy.max()], [y_test_noisy.min(), y_test_noisy.max()], 'r--', lw=2)\n",
    "axes_test[0,0].set_xlabel('Valores Reales')\n",
    "axes_test[0,0].set_ylabel('Predicciones')\n",
    "axes_test[0,0].set_title(f'Ensemble Optimizado (Prueba) - R² = {r2_test_opt:.4f}')\n",
    "axes_test[0,0].grid(True, alpha=0.3)\n",
    "\n",
    "residuos_test = y_test_noisy - y_pred_test_opt  # Usar y_test_noisy\n",
    "axes_test[0,1].scatter(y_pred_test_opt, residuos_test, alpha=0.6)\n",
    "axes_test[0,1].axhline(y=0, color='r', linestyle='--')\n",
    "axes_test[0,1].set_xlabel('Predicciones')\n",
    "axes_test[0,1].set_ylabel('Residuos')\n",
    "axes_test[0,1].set_title('Gráfico de Residuos (Prueba)')\n",
    "axes_test[0,1].grid(True, alpha=0.3)\n",
    "\n",
    "model_names = list(results.keys()) + ['GridSearchCV', 'RandomizedSearchCV', 'BayesSearchCV']\n",
    "mse_values = [results[m]['MSE'] for m in results] + [opt_results[m]['MSE'] for m in ['GridSearchCV', 'RandomizedSearchCV', 'BayesSearchCV']]\n",
    "r2_values = [results[m]['R²'] for m in results] + [opt_results[m]['R²'] for m in ['GridSearchCV', 'RandomizedSearchCV', 'BayesSearchCV']]\n",
    "\n",
    "x_pos = np.arange(len(model_names))\n",
    "axes_test[1,0].bar(x_pos, mse_values, alpha=0.7)\n",
    "axes_test[1,0].set_xlabel('Modelo')\n",
    "axes_test[1,0].set_ylabel('MSE')\n",
    "axes_test[1,0].set_title('Comparación MSE por Modelo')\n",
    "axes_test[1,0].set_xticks(x_pos)\n",
    "axes_test[1,0].set_xticklabels(model_names, rotation=45)\n",
    "\n",
    "axes_test[1,1].bar(x_pos, r2_values, alpha=0.7, color='green')\n",
    "axes_test[1,1].set_xlabel('Modelo')\n",
    "axes_test[1,1].set_ylabel('R²')\n",
    "axes_test[1,1].set_title('Comparación R² por Modelo')\n",
    "axes_test[1,1].set_xticks(x_pos)\n",
    "axes_test[1,1].set_xticklabels(model_names, rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "fig_test.savefig(f\"{output_dir}ensemble_comparative_analysis_test.png\", dpi=300, bbox_inches='tight')\n",
    "plt.close(fig_test)\n",
    "print(f\"📊 Gráfico de prueba guardado en: {output_dir}ensemble_comparative_analysis_test.png\")\n",
    "\n",
    "# Visualizaciones para el conjunto de entrenamiento\n",
    "fig_train, axes_train = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "axes_train[0].scatter(y_train, y_pred_train_opt, alpha=0.6)\n",
    "axes_train[0].plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], 'r--', lw=2)\n",
    "axes_train[0].set_xlabel('Valores Reales')\n",
    "axes_train[0].set_ylabel('Predicciones')\n",
    "axes_train[0].set_title(f'Ensemble Optimizado (Entrenamiento) - R² = {r2_train_opt:.4f}')\n",
    "axes_train[0].grid(True, alpha=0.3)\n",
    "\n",
    "residuos_train = y_train - y_pred_train_opt\n",
    "axes_train[1].scatter(y_pred_train_opt, residuos_train, alpha=0.6)\n",
    "axes_train[1].axhline(y=0, color='r', linestyle='--')\n",
    "axes_train[1].set_xlabel('Predicciones')\n",
    "axes_train[1].set_ylabel('Residuos')\n",
    "axes_train[1].set_title('Gráfico de Residuos (Entrenamiento)')\n",
    "axes_train[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "fig_train.savefig(f\"{output_dir}ensemble_comparative_analysis_train.png\", dpi=300, bbox_inches='tight')\n",
    "plt.close(fig_train)\n",
    "print(f\"📊 Gráfico de entrenamiento guardado en: {output_dir}ensemble_comparative_analysis_train.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb6eebe",
   "metadata": {},
   "source": [
    "## Resumen de Resultados de Modelos Ensemble\n",
    "La siguiente tabla presenta un resumen comparativo del desempeño de diferentes modelos de machine learning utilizados para predecir el consumo energético (Energy Consumption) en un dataset sintético. Los modelos evaluados incluyen Random Forest, Gradient Boosting, XGBoost (versión básica), y versiones optimizadas de XGBoost mediante GridSearchCV, RandomizedSearchCV, y BayesSearchCV, junto con los resultados del modelo XGBoost optimizado en los conjuntos de entrenamiento y prueba.\n",
    " \n",
    "## Descripción de las Métricas\n",
    " \n",
    "- Modelo: Nombre del modelo o método de optimización evaluado.\n",
    "- MSE (Error Cuadrático Medio): Promedio de los errores al cuadrado entre los valores reales y predichos, mide la magnitud de los errores.\n",
    "- RMSE (Raíz del Error Cuadrático Medio): Raíz cuadrada del MSE, proporciona una medida interpretable en la misma unidad que la variable objetivo.\n",
    "- R² (Coeficiente de Determinación): Indica la proporción de la varianza en la variable objetivo explicada por el modelo (valores cercanos a 1 indican mejor ajuste, ~0.6–0.9 es realista con datos ruidosos).\n",
    "- MAE (Error Absoluto Medio): Promedio de los errores absolutos, mide la magnitud promedio de los errores sin considerar su dirección.\n",
    "\n",
    "## Contexto\n",
    "Los datos incluyen ruido añadido (y_train_noisy, y_test_noisy) para simular un escenario realista, ya que el dataset original es sintético con una relación lineal perfecta. Las métricas reflejan el desempeño en el conjunto de prueba (excepto para \"XGBoost Optimizado (Entrenamiento)\"), con valores esperados de R² ~0.6–0.9 y RMSE ~400–600, dependiendo del nivel de ruido.\n",
    "\n",
    "## Uso\n",
    "Esta tabla permite comparar el desempeño de los modelos básicos y optimizados, identificando el mejor método (menor MSE en el conjunto de prueba). Los resultados se guardan en '../data/results/ensemble_resumen_resultados.csv' para análisis posterior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a0adff88",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RESUMEN DE RESULTADOS ===\n",
      "                               Modelo          MSE      RMSE      R²       MAE\n",
      "0                       Random Forest  232561.3204  482.2461  0.7586  388.5226\n",
      "1                   Gradient Boosting  252435.1228  502.4292  0.7380  397.0668\n",
      "2                             XGBoost  265444.2876  515.2129  0.7245  412.0864\n",
      "3                        GridSearchCV  238829.9856  488.7023  0.7521  393.0759\n",
      "4                  RandomizedSearchCV  242187.9053  492.1259  0.7486  390.9323\n",
      "5                       BayesSearchCV  256503.1255  506.4614  0.7338  404.6343\n",
      "6  XGBoost Optimizado (Entrenamiento)  152717.0443  390.7903  0.8594  312.1552\n",
      "7         XGBoost Optimizado (Prueba)  238829.9856  488.7023  0.7521  393.0759\n",
      "Resumen de resultados guardado en '../data/results/ensemble_resumen_resultados.csv'\n"
     ]
    }
   ],
   "source": [
    "# 9. TABLA RESUMEN DE RESULTADOS\n",
    "print(\"\\n=== RESUMEN DE RESULTADOS ===\")\n",
    "resumen = pd.DataFrame({\n",
    "    'Modelo': ['Random Forest', 'Gradient Boosting', 'XGBoost', 'GridSearchCV', 'RandomizedSearchCV', 'BayesSearchCV', 'XGBoost Optimizado (Entrenamiento)', 'XGBoost Optimizado (Prueba)'],\n",
    "    'MSE': [results['Random Forest']['MSE'], results['Gradient Boosting']['MSE'], results['XGBoost']['MSE'], \n",
    "            opt_results['GridSearchCV']['MSE'], opt_results['RandomizedSearchCV']['MSE'], opt_results['BayesSearchCV']['MSE'], \n",
    "            mse_train_opt, mse_test_opt],\n",
    "    'RMSE': [results['Random Forest']['RMSE'], results['Gradient Boosting']['RMSE'], results['XGBoost']['RMSE'], \n",
    "             opt_results['GridSearchCV']['RMSE'], opt_results['RandomizedSearchCV']['RMSE'], opt_results['BayesSearchCV']['RMSE'], \n",
    "             rmse_train_opt, rmse_test_opt],\n",
    "    'R²': [results['Random Forest']['R²'], results['Gradient Boosting']['R²'], results['XGBoost']['R²'], \n",
    "           opt_results['GridSearchCV']['R²'], opt_results['RandomizedSearchCV']['R²'], opt_results['BayesSearchCV']['R²'], \n",
    "           r2_train_opt, r2_test_opt],\n",
    "    'MAE': [results['Random Forest']['MAE'], results['Gradient Boosting']['MAE'], results['XGBoost']['MAE'], \n",
    "            opt_results['GridSearchCV']['MAE'], opt_results['RandomizedSearchCV']['MAE'], opt_results['BayesSearchCV']['MAE'], \n",
    "            mae_train_opt, mae_test_opt]\n",
    "})\n",
    "\n",
    "print(resumen.round(4))\n",
    "\n",
    "# Guardar la tabla resumen como CSV\n",
    "resumen.to_csv('../data/results/ensemble_resumen_resultados.csv', index=False)\n",
    "print(\"Resumen de resultados guardado en '../data/results/ensemble_resumen_resultados.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3f26572",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Modelo y scaler guardados como 'ensemble_model.pkl' y 'ensemble_scaler.pkl'\n"
     ]
    }
   ],
   "source": [
    "# 10. GUARDAR EL MODELO\n",
    "joblib.dump(ensemble_optimized, '../data/results/ensemble_model.pkl')\n",
    "joblib.dump(scaler, '../data/results/ensemble_scaler.pkl')\n",
    "print(\"\\nModelo y scaler guardados como 'ensemble_model.pkl' y 'ensemble_scaler.pkl'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f658e747",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "¡Modelos ensemble implementados exitosamente!\n"
     ]
    }
   ],
   "source": [
    "# 11. FUNCIÓN PARA NUEVAS PREDICCIONES\n",
    "def predecir_nuevos_datos(nuevos_datos, modelo=ensemble_optimized, escalador=scaler):\n",
    "    \"\"\"\n",
    "    Función para hacer predicciones en nuevos datos\n",
    "    \n",
    "    Parameters:\n",
    "    nuevos_datos: array-like o DataFrame, datos a predecir\n",
    "    modelo: modelo ensemble entrenado\n",
    "    escalador: StandardScaler ajustado\n",
    "    \n",
    "    Returns:\n",
    "    predicciones: array con las predicciones\n",
    "    \"\"\"\n",
    "    if isinstance(nuevos_datos, pd.DataFrame):\n",
    "        nuevos_datos = nuevos_datos.values\n",
    "    datos_escalados = escalador.transform(nuevos_datos)\n",
    "    predicciones = modelo.predict(datos_escalados)\n",
    "    return predicciones\n",
    "\n",
    "print(\"\\n¡Modelos ensemble implementados exitosamente!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
