{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0128bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import cross_val_score, train_test_split, GridSearchCV, RandomizedSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import joblib\n",
    "import warnings\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Integer\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configurar estilo de gráficos\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette('husl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f79d1534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. CARGAR Y PREPARAR LOS DATOS\n",
    "train_df = pd.read_csv('../data/processed/energy_data_processed.csv')\n",
    "test_df = pd.read_csv('../data/processed/energy_data_processed_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbc71bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma del dataset de entrenamiento: (1000, 9)\n",
      "Forma del dataset de prueba: (1000, 9)\n",
      "Variable objetivo: Energy Consumption\n"
     ]
    }
   ],
   "source": [
    "# 2. SEPARAR CARACTERÍSTICAS Y VARIABLE OBJETIVO\n",
    "y_train = train_df['Energy Consumption']\n",
    "X_train = train_df.drop('Energy Consumption', axis=1)\n",
    "y_test = test_df['Energy Consumption']\n",
    "X_test = test_df.drop('Energy Consumption', axis=1)\n",
    "\n",
    "# Verificar tamaños\n",
    "print(f'Forma del dataset de entrenamiento: {X_train.shape}')\n",
    "print(f'Forma del dataset de prueba: {X_test.shape}')\n",
    "print(f'Variable objetivo: {y_train.name}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "228ebd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. ESCALADO DE CARACTERÍSTICAS (opcional para árboles, pero útil para consistencia)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "273364dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Random Forest BÁSICO ===\n",
      "MSE: 2097.7550\n",
      "RMSE: 45.8013\n",
      "R²: 0.9976\n",
      "MAE: 36.0567\n",
      "\n",
      "=== Gradient Boosting BÁSICO ===\n",
      "MSE: 2536.2069\n",
      "RMSE: 50.3608\n",
      "R²: 0.9971\n",
      "MAE: 39.1547\n",
      "\n",
      "=== XGBoost BÁSICO ===\n",
      "MSE: 29.4600\n",
      "RMSE: 5.4277\n",
      "R²: 1.0000\n",
      "MAE: 3.8408\n",
      "\n",
      "XGBoost - Entrenamiento: R² = 1.0000, MSE = 29.4600\n",
      "XGBoost - Prueba: R² = 1.0000, MSE = 29.4600\n",
      "\n",
      "Ejemplo de 5 predicciones vs reales (Prueba):\n",
      "Real: 3463.09, Pred: 3463.11, Diferencia: 0.02\n",
      "Real: 5219.66, Pred: 5218.00, Diferencia: 1.66\n",
      "Real: 3106.77, Pred: 3099.42, Diferencia: 7.35\n",
      "Real: 4922.82, Pred: 4917.68, Diferencia: 5.14\n",
      "Real: 4687.67, Pred: 4677.81, Diferencia: 9.86\n",
      "\n",
      "Tamaños: Train=1000, Test=1000\n",
      "\n",
      "Primeras 5 filas de X_test:\n",
      "   Square Footage  Number of Occupants  Appliances Used  Average Temperature  \\\n",
      "0            7063                   76               10                29.84   \n",
      "1           44372                   66               45                16.72   \n",
      "2           19255                   37               17                14.30   \n",
      "3           13265                   14               41                32.82   \n",
      "4           13375                   26               18                11.92   \n",
      "\n",
      "   Building Type_Commercial  Building Type_Industrial  \\\n",
      "0                     False                     False   \n",
      "1                      True                     False   \n",
      "2                     False                      True   \n",
      "3                     False                     False   \n",
      "4                      True                     False   \n",
      "\n",
      "   Building Type_Residential  Day of Week_Weekday  Day of Week_Weekend  \n",
      "0                       True                 True                False  \n",
      "1                      False                 True                False  \n",
      "2                      False                False                 True  \n",
      "3                       True                 True                False  \n",
      "4                      False                 True                False  \n",
      "\n",
      "Primeras 5 filas de y_test:\n",
      "0    2713.95\n",
      "1    5744.99\n",
      "2    4101.24\n",
      "3    3009.14\n",
      "4    3279.17\n",
      "Name: Energy Consumption, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 4. MODELOS ENSEMBLE\n",
    "models = {\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42, max_depth=10, min_samples_split=5, min_samples_leaf=2),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, random_state=42, max_depth=5, min_samples_split=5, min_samples_leaf=2),\n",
    "    'XGBoost': XGBRegressor(n_estimators=50, random_state=42, eval_metric='rmse', max_depth=3, reg_alpha=1.0, reg_lambda=2.0, gamma=0.5)\n",
    "}\n",
    "\n",
    "# Entrenar y evaluar modelos básicos\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    print(f'\\n=== {name} BÁSICO ===')\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred_test = model.predict(X_test_scaled)\n",
    "    \n",
    "    mse = mean_squared_error(y_test, y_pred_test)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_pred_test)\n",
    "    mae = mean_absolute_error(y_test, y_pred_test)\n",
    "    \n",
    "    results[name] = {'MSE': mse, 'RMSE': rmse, 'R²': r2, 'MAE': mae}\n",
    "    print(f\"MSE: {mse:.4f}\")\n",
    "    print(f\"RMSE: {rmse:.4f}\")\n",
    "    print(f\"R²: {r2:.4f}\")\n",
    "    print(f\"MAE: {mae:.4f}\")\n",
    "\n",
    "# Diagnóstico para XGBoost\n",
    "# Agregar después del bucle for en la celda 3 (después de entrenar los modelos básicos)\n",
    "y_pred_train_xgb = models['XGBoost'].predict(X_train_scaled)\n",
    "mse_train_xgb = mean_squared_error(y_train, y_pred_train_xgb)\n",
    "r2_train_xgb = r2_score(y_train, y_pred_train_xgb)\n",
    "print(f\"\\nXGBoost - Entrenamiento: R² = {r2_train_xgb:.4f}, MSE = {mse_train_xgb:.4f}\")\n",
    "print(f\"XGBoost - Prueba: R² = {results['XGBoost']['R²']:.4f}, MSE = {results['XGBoost']['MSE']:.4f}\")\n",
    "\n",
    "# Ejemplo de 5 predicciones vs reales en prueba\n",
    "y_pred_test_xgb = models['XGBoost'].predict(X_test_scaled)\n",
    "print(\"\\nEjemplo de 5 predicciones vs reales (Prueba):\")\n",
    "sample_idx = np.random.choice(len(y_test), min(5, len(y_test)), replace=False)\n",
    "for i in sample_idx:\n",
    "    print(f\"Real: {y_test.iloc[i]:.2f}, Pred: {y_pred_test_xgb[i]:.2f}, Diferencia: {abs(y_test.iloc[i] - y_pred_test_xgb[i]):.2f}\")\n",
    "# Tamaño de datasets\n",
    "print(f\"\\nTamaños: Train={len(y_train)}, Test={len(y_test)}\")\n",
    "\n",
    "# Inspección de datos\n",
    "print(\"\\nPrimeras 5 filas de X_test:\")\n",
    "print(X_test.head())\n",
    "print(\"\\nPrimeras 5 filas de y_test:\")\n",
    "print(y_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee6f34b7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "¡SVR implementado exitosamente!\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n=== DIAGNÓSTICO ADICIONAL ===\")\n",
    "\n",
    "# Correlaciones entre características y variable objetivo\n",
    "correlations = X_train.corrwith(y_train)\n",
    "print(\"\\nCorrelaciones entre características y 'Energy Consumption':\")\n",
    "print(correlations.sort_values(ascending=False))\n",
    "\n",
    "# Validación cruzada para XGBoost básico\n",
    "cv_scores = cross_val_score(models['XGBoost'], X_train_scaled, y_train, cv=5, scoring='r2')\n",
    "print(f\"\\nValidación cruzada (5-fold) para XGBoost - R²: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
    "\n",
    "# Comparar primeras filas de X_train y X_test\n",
    "print(\"\\nPrimeras 5 filas de X_train:\")\n",
    "print(X_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b88fea17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Mejores parámetros para XGBoost: OrderedDict({'colsample_bytree': 0.8155553746682142, 'learning_rate': 0.15943036309640915, 'max_depth': 3, 'n_estimators': 200, 'subsample': 0.6})\n",
      "Mejor score CV: 5645.3567\n"
     ]
    }
   ],
   "source": [
    "# 5. OPTIMIZACIÓN CON BAYESIAN SEARCH PARA XGBoost (ejemplo, puedes extender a otros)\n",
    "# Optimización de hiperparámetros para XGBoost\n",
    "print(\"\\n=== OPTIMIZACIÓN DE HIPERPARÁMETROS PARA XGBOOST ===\")\n",
    "\n",
    "# Definir espacio de hiperparámetros común\n",
    "param_grid = {\n",
    "    'n_estimators': [50, 100, 200],\n",
    "    'max_depth': [3, 5, 8],\n",
    "    'learning_rate': [0.01, 0.1, 0.3],\n",
    "    'subsample': [0.6, 0.8, 1.0],\n",
    "    'colsample_bytree': [0.6, 0.8, 1.0],\n",
    "    'reg_alpha': [0.0, 0.5, 1.0],\n",
    "    'reg_lambda': [0.0, 1.0, 2.0],\n",
    "    'gamma': [0.0, 0.3, 0.5]\n",
    "}\n",
    "\n",
    "# 1. GridSearchCV\n",
    "print(\"\\n--- GridSearchCV ---\")\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=XGBRegressor(random_state=42, eval_metric='rmse'),\n",
    "    param_grid={\n",
    "        'n_estimators': [50, 100],\n",
    "        'max_depth': [3, 5],\n",
    "        'learning_rate': [0.1, 0.3],\n",
    "        'subsample': [0.8, 1.0],\n",
    "        'colsample_bytree': [0.8, 1.0],\n",
    "        'reg_alpha': [0.0, 1.0],\n",
    "        'reg_lambda': [1.0, 2.0]\n",
    "    },\n",
    "    cv=5,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1,\n",
    "    verbose=1\n",
    ")\n",
    "grid_search.fit(X_train_scaled, y_train)\n",
    "grid_best = grid_search.best_estimator_\n",
    "grid_score = -grid_search.best_score_\n",
    "print(f\"Mejores parámetros (GridSearchCV): {grid_search.best_params_}\")\n",
    "print(f\"Mejor MSE CV (GridSearchCV): {grid_score:.4f}\")\n",
    "\n",
    "# 2. RandomizedSearchCV\n",
    "print(\"\\n--- RandomizedSearchCV ---\")\n",
    "random_search = RandomizedSearchCV(\n",
    "    estimator=XGBRegressor(random_state=42, eval_metric='rmse'),\n",
    "    param_distributions=param_grid,\n",
    "    n_iter=50,\n",
    "    cv=5,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    random_state=42\n",
    ")\n",
    "random_search.fit(X_train_scaled, y_train)\n",
    "random_best = random_search.best_estimator_\n",
    "random_score = -random_search.best_score_\n",
    "print(f\"Mejores parámetros (RandomizedSearchCV): {random_search.best_params_}\")\n",
    "print(f\"Mejor MSE CV (RandomizedSearchCV): {random_score:.4f}\")\n",
    "\n",
    "# 3. BayesSearchCV\n",
    "print(\"\\n--- BayesSearchCV ---\")\n",
    "bayes_search = BayesSearchCV(\n",
    "    estimator=XGBRegressor(random_state=42, eval_metric='rmse'),\n",
    "    search_spaces={\n",
    "        'n_estimators': Integer(50, 200),\n",
    "        'max_depth': Integer(3, 8),\n",
    "        'learning_rate': Real(0.01, 0.3, prior='log-uniform'),\n",
    "        'subsample': Real(0.6, 1.0),\n",
    "        'colsample_bytree': Real(0.6, 1.0),\n",
    "        'reg_alpha': Real(0.0, 1.0),\n",
    "        'reg_lambda': Real(0.0, 2.0),\n",
    "        'gamma': Real(0.0, 0.5)\n",
    "    },\n",
    "    n_iter=50,\n",
    "    cv=5,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    random_state=42\n",
    ")\n",
    "# Agregar early stopping\n",
    "X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(X_train_scaled, y_train, test_size=0.2, random_state=42)\n",
    "bayes_search.fit(X_train_split, y_train_split, early_stopping_rounds=10, eval_set=[(X_val_split, y_val_split)], verbose=False)\n",
    "bayes_best = bayes_search.best_estimator_\n",
    "bayes_score = -bayes_search.best_score_\n",
    "print(f\"Mejores parámetros (BayesSearchCV): {bayes_search.best_params_}\")\n",
    "print(f\"Mejor MSE CV (BayesSearchCV): {bayes_score:.4f}\")\n",
    "\n",
    "# Comparar resultados\n",
    "print(\"\\n=== COMPARACIÓN DE MÉTODOS DE OPTIMIZACIÓN ===\")\n",
    "opt_results = {}\n",
    "for name, model in [('GridSearchCV', grid_best), ('RandomizedSearchCV', random_best), ('BayesSearchCV', bayes_best)]:\n",
    "    y_pred_test = model.predict(X_test_scaled)\n",
    "    mse = mean_squared_error(y_test, y_pred_test)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_pred_test)\n",
    "    mae = mean_absolute_error(y_test, y_pred_test)\n",
    "    opt_results[name] = {'MSE': mse, 'RMSE': rmse, 'R²': r2, 'MAE': mae}\n",
    "    print(f\"\\n{name} (Prueba):\")\n",
    "    print(f\"MSE: {mse:.4f}\")\n",
    "    print(f\"RMSE: {rmse:.4f}\")\n",
    "    print(f\"R²: {r2:.4f}\")\n",
    "    print(f\"MAE: {mae:.4f}\")\n",
    "\n",
    "# Seleccionar el mejor modelo\n",
    "best_method = min(opt_results, key=lambda x: opt_results[x]['MSE'])\n",
    "ensemble_optimized = {'GridSearchCV': grid_best, 'RandomizedSearchCV': random_best, 'BayesSearchCV': bayes_best}[best_method]\n",
    "print(f\"\\nMejor método: {best_method} (MSE: {opt_results[best_method]['MSE']:.4f})\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19c507bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== MODELO OPTIMIZADO (ENTRENAMIENTO) ===\n",
      "MSE: 1246.6236\n",
      "RMSE: 35.3076\n",
      "R²: 0.9986\n",
      "MAE: 27.7898\n",
      "\n",
      "=== MODELO OPTIMIZADO (PRUEBA) ===\n",
      "MSE: 1246.6236\n",
      "RMSE: 35.3076\n",
      "R²: 0.9986\n",
      "MAE: 27.7898\n",
      "\n",
      "CV RMSE: 67.4988 (+/- 36.0738)\n"
     ]
    }
   ],
   "source": [
    "# 6. MODELO OPTIMIZADO (usamos XGBoost optimizado como ejemplo principal)\n",
    "y_pred_train_opt = ensemble_optimized.predict(X_train_scaled)\n",
    "y_pred_test_opt = ensemble_optimized.predict(X_test_scaled)\n",
    "\n",
    "# Métricas para entrenamiento\n",
    "mse_train_opt = mean_squared_error(y_train, y_pred_train_opt)\n",
    "rmse_train_opt = np.sqrt(mse_train_opt)\n",
    "r2_train_opt = r2_score(y_train, y_pred_train_opt)\n",
    "mae_train_opt = mean_absolute_error(y_train, y_pred_train_opt)\n",
    "\n",
    "# Métricas para prueba\n",
    "mse_test_opt = mean_squared_error(y_test, y_pred_test_opt)\n",
    "rmse_test_opt = np.sqrt(mse_test_opt)\n",
    "r2_test_opt = r2_score(y_test, y_pred_test_opt)\n",
    "mae_test_opt = mean_absolute_error(y_test, y_pred_test_opt)\n",
    "\n",
    "print(f'\\n=== MODELO OPTIMIZADO (ENTRENAMIENTO) ===')\n",
    "print(f'MSE: {mse_train_opt:.4f}')\n",
    "print(f'RMSE: {rmse_train_opt:.4f}')\n",
    "print(f'R²: {r2_train_opt:.4f}')\n",
    "print(f'MAE: {mae_train_opt:.4f}')\n",
    "\n",
    "print(f'\\n=== MODELO OPTIMIZADO (PRUEBA) ===')\n",
    "print(f'MSE: {mse_test_opt:.4f}')\n",
    "print(f'RMSE: {rmse_test_opt:.4f}')\n",
    "print(f'R²: {r2_test_opt:.4f}')\n",
    "print(f'MAE: {mae_test_opt:.4f}')\n",
    "\n",
    "# Validación cruzada\n",
    "cv_scores = cross_val_score(ensemble_optimized, X_train_scaled, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "print(f'\\nCV RMSE: {np.sqrt(-cv_scores.mean()):.4f} (+/- {np.sqrt(cv_scores.std() * 2):.4f})')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4666f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicciones de entrenamiento guardadas en '../data/results/ensemble_predictions_train.csv'\n",
      "Predicciones de prueba guardadas en '../data/results/ensemble_predictions_test.csv'\n"
     ]
    }
   ],
   "source": [
    "# 7. GUARDAR RESULTADOS EN CSV\n",
    "train_results = pd.DataFrame({\n",
    "    'Valores Reales': y_train,\n",
    "    'Predicciones': y_pred_train_opt,\n",
    "    'Diferencia': y_train - y_pred_train_opt\n",
    "})\n",
    "train_results.to_csv('../data/results/ensemble_predictions_train.csv', index=False)\n",
    "print(\"\\nPredicciones de entrenamiento guardadas en '../data/results/ensemble_predictions_train.csv'\")\n",
    "\n",
    "test_results = pd.DataFrame({\n",
    "    'Valores Reales': y_test,\n",
    "    'Predicciones': y_pred_test_opt,\n",
    "    'Diferencia': y_test - y_pred_test_opt\n",
    "})\n",
    "test_results.to_csv('../data/results/ensemble_predictions_test.csv', index=False)\n",
    "print(\"Predicciones de prueba guardadas en '../data/results/ensemble_predictions_test.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462dd49d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📊 Gráfico de prueba guardado en: ../data/figures/ensemble_comparative_analysis_test.png\n",
      "📊 Gráfico de entrenamiento guardado en: ../data/figures/ensemble_comparative_analysis_train.png\n"
     ]
    }
   ],
   "source": [
    "# 8. VISUALIZACIONES\n",
    "output_dir = \"../data/figures/\"\n",
    "\n",
    "# Visualizaciones para el conjunto de prueba\n",
    "fig_test, axes_test = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "axes_test[0,0].scatter(y_test, y_pred_test_opt, alpha=0.6)\n",
    "axes_test[0,0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "axes_test[0,0].set_xlabel('Valores Reales')\n",
    "axes_test[0,0].set_ylabel('Predicciones')\n",
    "axes_test[0,0].set_title(f'Ensemble Optimizado (Prueba) - R² = {r2_test_opt:.4f}')\n",
    "axes_test[0,0].grid(True, alpha=0.3)\n",
    "\n",
    "residuos_test = y_test - y_pred_test_opt\n",
    "axes_test[0,1].scatter(y_pred_test_opt, residuos_test, alpha=0.6)\n",
    "axes_test[0,1].axhline(y=0, color='r', linestyle='--')\n",
    "axes_test[0,1].set_xlabel('Predicciones')\n",
    "axes_test[0,1].set_ylabel('Residuos')\n",
    "axes_test[0,1].set_title('Gráfico de Residuos (Prueba)')\n",
    "axes_test[0,1].grid(True, alpha=0.3)\n",
    "\n",
    "model_names = list(results.keys()) + ['GridSearchCV', 'RandomizedSearchCV', 'BayesSearchCV']\n",
    "mse_values = [results[m]['MSE'] for m in results] + [opt_results[m]['MSE'] for m in ['GridSearchCV', 'RandomizedSearchCV', 'BayesSearchCV']]\n",
    "r2_values = [results[m]['R²'] for m in results] + [opt_results[m]['R²'] for m in ['GridSearchCV', 'RandomizedSearchCV', 'BayesSearchCV']]\n",
    "\n",
    "x_pos = np.arange(len(model_names))\n",
    "axes_test[1,0].bar(x_pos, mse_values, alpha=0.7)\n",
    "axes_test[1,0].set_xlabel('Modelo')\n",
    "axes_test[1,0].set_ylabel('MSE')\n",
    "axes_test[1,0].set_title('Comparación MSE por Modelo')\n",
    "axes_test[1,0].set_xticks(x_pos)\n",
    "axes_test[1,0].set_xticklabels(model_names, rotation=45)\n",
    "\n",
    "axes_test[1,1].bar(x_pos, r2_values, alpha=0.7, color='green')\n",
    "axes_test[1,1].set_xlabel('Modelo')\n",
    "axes_test[1,1].set_ylabel('R²')\n",
    "axes_test[1,1].set_title('Comparación R² por Modelo')\n",
    "axes_test[1,1].set_xticks(x_pos)\n",
    "axes_test[1,1].set_xticklabels(model_names, rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "fig_test.savefig(f\"{output_dir}ensemble_comparative_analysis_test.png\", dpi=300, bbox_inches='tight')\n",
    "plt.close(fig_test)\n",
    "print(f\"📊 Gráfico de prueba guardado en: {output_dir}ensemble_comparative_analysis_test.png\")\n",
    "\n",
    "# Visualizaciones para el conjunto de entrenamiento\n",
    "fig_train, axes_train = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "axes_train[0].scatter(y_train, y_pred_train_opt, alpha=0.6)\n",
    "axes_train[0].plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], 'r--', lw=2)\n",
    "axes_train[0].set_xlabel('Valores Reales')\n",
    "axes_train[0].set_ylabel('Predicciones')\n",
    "axes_train[0].set_title(f'Ensemble Optimizado (Entrenamiento) - R² = {r2_train_opt:.4f}')\n",
    "axes_train[0].grid(True, alpha=0.3)\n",
    "\n",
    "residuos_train = y_train - y_pred_train_opt\n",
    "axes_train[1].scatter(y_pred_train_opt, residuos_train, alpha=0.6)\n",
    "axes_train[1].axhline(y=0, color='r', linestyle='--')\n",
    "axes_train[1].set_xlabel('Predicciones')\n",
    "axes_train[1].set_ylabel('Residuos')\n",
    "axes_train[1].set_title('Gráfico de Residuos (Entrenamiento)')\n",
    "axes_train[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "fig_train.savefig(f\"{output_dir}ensemble_comparative_analysis_train.png\", dpi=300, bbox_inches='tight')\n",
    "plt.close(fig_train)\n",
    "print(f\"📊 Gráfico de entrenamiento guardado en: {output_dir}ensemble_comparative_analysis_train.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da75ce8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RESUMEN DE RESULTADOS ===\n",
      "                              Modelo        MSE     RMSE      R²      MAE\n",
      "Random Forest          Random Forest  2097.7550  45.8013  0.9976  36.0567\n",
      "Gradient Boosting  Gradient Boosting  2536.2069  50.3608  0.9971  39.1547\n",
      "XGBoost                      XGBoost    29.4600   5.4277  1.0000   3.8408\n"
     ]
    }
   ],
   "source": [
    "# 9. TABLA RESUMEN DE RESULTADOS\n",
    "print(\"\\n=== RESUMEN DE RESULTADOS ===\")\n",
    "resumen = pd.DataFrame({\n",
    "    'Modelo': ['Random Forest', 'Gradient Boosting', 'XGBoost', 'GridSearchCV', 'RandomizedSearchCV', 'BayesSearchCV', 'XGBoost Optimizado (Entrenamiento)', 'XGBoost Optimizado (Prueba)'],\n",
    "    'MSE': [results['Random Forest']['MSE'], results['Gradient Boosting']['MSE'], results['XGBoost']['MSE'], \n",
    "            opt_results['GridSearchCV']['MSE'], opt_results['RandomizedSearchCV']['MSE'], opt_results['BayesSearchCV']['MSE'], \n",
    "            mse_train_opt, mse_test_opt],\n",
    "    'RMSE': [results['Random Forest']['RMSE'], results['Gradient Boosting']['RMSE'], results['XGBoost']['RMSE'], \n",
    "             opt_results['GridSearchCV']['RMSE'], opt_results['RandomizedSearchCV']['RMSE'], opt_results['BayesSearchCV']['RMSE'], \n",
    "             rmse_train_opt, rmse_test_opt],\n",
    "    'R²': [results['Random Forest']['R²'], results['Gradient Boosting']['R²'], results['XGBoost']['R²'], \n",
    "           opt_results['GridSearchCV']['R²'], opt_results['RandomizedSearchCV']['R²'], opt_results['BayesSearchCV']['R²'], \n",
    "           r2_train_opt, r2_test_opt],\n",
    "    'MAE': [results['Random Forest']['MAE'], results['Gradient Boosting']['MAE'], results['XGBoost']['MAE'], \n",
    "            opt_results['GridSearchCV']['MAE'], opt_results['RandomizedSearchCV']['MAE'], opt_results['BayesSearchCV']['MAE'], \n",
    "            mae_train_opt, mae_test_opt]\n",
    "})\n",
    "print(resumen.round(4))\n",
    "\n",
    "# Guardar la tabla resumen como CSV\n",
    "resumen.to_csv('../data/results/ensemble_resumen_resultados.csv', index=False)\n",
    "print(\"Resumen de resultados guardado en '../data/results/ensemble_resumen_resultados.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ffc767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Modelo y scaler guardados como 'ensemble_model.pkl' y 'ensemble_scaler.pkl'\n"
     ]
    }
   ],
   "source": [
    "# 10. GUARDAR EL MODELO\n",
    "joblib.dump(ensemble_optimized, '../data/results/ensemble_model.pkl')\n",
    "joblib.dump(scaler, '../data/results/ensemble_scaler.pkl')\n",
    "print(\"\\nModelo y scaler guardados como 'ensemble_model.pkl' y 'ensemble_scaler.pkl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba924d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "¡Modelos ensemble implementados exitosamente!\n"
     ]
    }
   ],
   "source": [
    "# 11. FUNCIÓN PARA NUEVAS PREDICCIONES\n",
    "def predecir_nuevos_datos(nuevos_datos, modelo=ensemble_optimized, escalador=scaler):\n",
    "    \"\"\"\n",
    "    Función para hacer predicciones en nuevos datos\n",
    "    \n",
    "    Parameters:\n",
    "    nuevos_datos: array-like o DataFrame, datos a predecir\n",
    "    modelo: modelo ensemble entrenado\n",
    "    escalador: StandardScaler ajustado\n",
    "    \n",
    "    Returns:\n",
    "    predicciones: array con las predicciones\n",
    "    \"\"\"\n",
    "    if isinstance(nuevos_datos, pd.DataFrame):\n",
    "        nuevos_datos = nuevos_datos.values\n",
    "    datos_escalados = escalador.transform(nuevos_datos)\n",
    "    predicciones = modelo.predict(datos_escalados)\n",
    "    return predicciones\n",
    "\n",
    "print(\"\\n¡Modelos ensemble implementados exitosamente!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
