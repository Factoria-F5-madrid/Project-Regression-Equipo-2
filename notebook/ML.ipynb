{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e0128bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from xgboost import XGBRegressor\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import joblib\n",
    "import warnings\n",
    "\n",
    "from skopt import BayesSearchCV\n",
    "from skopt.space import Real, Categorical, Integer\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Configurar estilo de gr치ficos\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f79d1534",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. CARGAR Y PREPARAR LOS DATOS\n",
    "train_df = pd.read_csv('../data/processed/energy_data_processed.csv')\n",
    "test_df = pd.read_csv('../data/processed/energy_data_processed_test.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fdbc71bd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Forma del dataset de entrenamiento: (1000, 9)\n",
      "Forma del dataset de prueba: (1000, 9)\n",
      "Variable objetivo: Energy Consumption\n"
     ]
    }
   ],
   "source": [
    "# 2. SEPARAR CARACTER칈STICAS Y VARIABLE OBJETIVO\n",
    "y_train = train_df['Energy Consumption']\n",
    "X_train = train_df.drop('Energy Consumption', axis=1)\n",
    "\n",
    "y_test = test_df['Energy Consumption']\n",
    "X_test = test_df.drop('Energy Consumption', axis=1)\n",
    "\n",
    "print(f\"Forma del dataset de entrenamiento: {X_train.shape}\")\n",
    "print(f\"Forma del dataset de prueba: {X_test.shape}\")\n",
    "print(f\"Variable objetivo: {y_train.name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "228ebd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 3. ESCALADO DE CARACTER칈STICAS (opcional para 치rboles, pero 칰til para consistencia)\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "273364dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Random Forest B츼SICO ===\n",
      "MSE: 2097.7550\n",
      "RMSE: 45.8013\n",
      "R: 0.9976\n",
      "MAE: 36.0567\n",
      "\n",
      "=== Gradient Boosting B츼SICO ===\n",
      "MSE: 2536.2069\n",
      "RMSE: 50.3608\n",
      "R: 0.9971\n",
      "MAE: 39.1547\n",
      "\n",
      "=== XGBoost B츼SICO ===\n",
      "MSE: 29.4600\n",
      "RMSE: 5.4277\n",
      "R: 1.0000\n",
      "MAE: 3.8408\n",
      "\n",
      "XGBoost - Entrenamiento: R = 1.0000, MSE = 29.4600\n",
      "XGBoost - Prueba: R = 1.0000, MSE = 29.4600\n",
      "\n",
      "Ejemplo de 5 predicciones vs reales (Prueba):\n",
      "Real: 3463.09, Pred: 3463.11, Diferencia: 0.02\n",
      "Real: 5219.66, Pred: 5218.00, Diferencia: 1.66\n",
      "Real: 3106.77, Pred: 3099.42, Diferencia: 7.35\n",
      "Real: 4922.82, Pred: 4917.68, Diferencia: 5.14\n",
      "Real: 4687.67, Pred: 4677.81, Diferencia: 9.86\n",
      "\n",
      "Tama침os: Train=1000, Test=1000\n",
      "\n",
      "Primeras 5 filas de X_test:\n",
      "   Square Footage  Number of Occupants  Appliances Used  Average Temperature  \\\n",
      "0            7063                   76               10                29.84   \n",
      "1           44372                   66               45                16.72   \n",
      "2           19255                   37               17                14.30   \n",
      "3           13265                   14               41                32.82   \n",
      "4           13375                   26               18                11.92   \n",
      "\n",
      "   Building Type_Commercial  Building Type_Industrial  \\\n",
      "0                     False                     False   \n",
      "1                      True                     False   \n",
      "2                     False                      True   \n",
      "3                     False                     False   \n",
      "4                      True                     False   \n",
      "\n",
      "   Building Type_Residential  Day of Week_Weekday  Day of Week_Weekend  \n",
      "0                       True                 True                False  \n",
      "1                      False                 True                False  \n",
      "2                      False                False                 True  \n",
      "3                       True                 True                False  \n",
      "4                      False                 True                False  \n",
      "\n",
      "Primeras 5 filas de y_test:\n",
      "0    2713.95\n",
      "1    5744.99\n",
      "2    4101.24\n",
      "3    3009.14\n",
      "4    3279.17\n",
      "Name: Energy Consumption, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# 4. MODELOS ENSEMBLE\n",
    "models = {\n",
    "    'Random Forest': RandomForestRegressor(n_estimators=100, random_state=42),\n",
    "    'Gradient Boosting': GradientBoostingRegressor(n_estimators=100, random_state=42),\n",
    "    'XGBoost': XGBRegressor(n_estimators=100, random_state=42, eval_metric='rmse')\n",
    "}\n",
    "\n",
    "# Entrenar y evaluar modelos b치sicos\n",
    "results = {}\n",
    "for name, model in models.items():\n",
    "    print(f\"\\n=== {name} B츼SICO ===\")\n",
    "    model.fit(X_train_scaled, y_train)\n",
    "    y_pred_test = model.predict(X_test_scaled)\n",
    "    \n",
    "    mse = mean_squared_error(y_test, y_pred_test)\n",
    "    rmse = np.sqrt(mse)\n",
    "    r2 = r2_score(y_test, y_pred_test)\n",
    "    mae = mean_absolute_error(y_test, y_pred_test)\n",
    "    \n",
    "    results[name] = {'MSE': mse, 'RMSE': rmse, 'R': r2, 'MAE': mae}\n",
    "\n",
    "    print(f\"MSE: {mse:.4f}\")\n",
    "    print(f\"RMSE: {rmse:.4f}\")\n",
    "    print(f\"R: {r2:.4f}\")\n",
    "    print(f\"MAE: {mae:.4f}\")\n",
    "\n",
    "# Diagn칩stico para XGBoost\n",
    "# Agregar despu칠s del bucle for en la celda 3 (despu칠s de entrenar los modelos b치sicos)\n",
    "y_pred_train_xgb = models['XGBoost'].predict(X_train_scaled)\n",
    "mse_train_xgb = mean_squared_error(y_train, y_pred_train_xgb)\n",
    "r2_train_xgb = r2_score(y_train, y_pred_train_xgb)\n",
    "print(f\"\\nXGBoost - Entrenamiento: R = {r2_train_xgb:.4f}, MSE = {mse_train_xgb:.4f}\")\n",
    "print(f\"XGBoost - Prueba: R = {results['XGBoost']['R']:.4f}, MSE = {results['XGBoost']['MSE']:.4f}\")\n",
    "\n",
    "# Ejemplo de 5 predicciones vs reales en prueba\n",
    "y_pred_test_xgb = models['XGBoost'].predict(X_test_scaled)\n",
    "print(\"\\nEjemplo de 5 predicciones vs reales (Prueba):\")\n",
    "sample_idx = np.random.choice(len(y_test), min(5, len(y_test)), replace=False)\n",
    "for i in sample_idx:\n",
    "    print(f\"Real: {y_test.iloc[i]:.2f}, Pred: {y_pred_test_xgb[i]:.2f}, Diferencia: {abs(y_test.iloc[i] - y_pred_test_xgb[i]):.2f}\")\n",
    "\n",
    "# Tama침o de datasets\n",
    "print(f\"\\nTama침os: Train={len(y_train)}, Test={len(y_test)}\")\n",
    "\n",
    "# Inspecci칩n de datos\n",
    "print(\"\\nPrimeras 5 filas de X_test:\")\n",
    "print(X_test.head())\n",
    "print(\"\\nPrimeras 5 filas de y_test:\")\n",
    "print(y_test.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb4af7f4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== DIAGN칍STICO ADICIONAL ===\n",
      "Filas duplicadas entre train y test: 1000\n",
      "\n",
      "Correlaciones entre caracter칤sticas y 'Energy Consumption':\n",
      "Square Footage               0.774873\n",
      "Building Type_Industrial     0.415468\n",
      "Number of Occupants          0.354485\n",
      "Appliances Used              0.312792\n",
      "Day of Week_Weekday          0.004393\n",
      "Day of Week_Weekend         -0.004393\n",
      "Building Type_Commercial    -0.027627\n",
      "Average Temperature         -0.034487\n",
      "Building Type_Residential   -0.378708\n",
      "dtype: float64\n",
      "\n",
      "Validaci칩n cruzada (5-fold) para XGBoost - R: 0.9839 (+/- 0.0042)\n",
      "\n",
      "Primeras 5 filas de X_train:\n",
      "   Square Footage  Number of Occupants  Appliances Used  Average Temperature  \\\n",
      "0            7063                   76               10                29.84   \n",
      "1           44372                   66               45                16.72   \n",
      "2           19255                   37               17                14.30   \n",
      "3           13265                   14               41                32.82   \n",
      "4           13375                   26               18                11.92   \n",
      "\n",
      "   Building Type_Commercial  Building Type_Industrial  \\\n",
      "0                     False                     False   \n",
      "1                      True                     False   \n",
      "2                     False                      True   \n",
      "3                     False                     False   \n",
      "4                      True                     False   \n",
      "\n",
      "   Building Type_Residential  Day of Week_Weekday  Day of Week_Weekend  \n",
      "0                       True                 True                False  \n",
      "1                      False                 True                False  \n",
      "2                      False                False                 True  \n",
      "3                       True                 True                False  \n",
      "4                      False                 True                False  \n"
     ]
    }
   ],
   "source": [
    "# Celda adicional: Diagn칩stico de fuga de datos y correlaciones\n",
    "print(\"\\n=== DIAGN칍STICO ADICIONAL ===\")\n",
    "\n",
    "# 1. Verificar duplicados entre train y test\n",
    "X_train_df = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "X_test_df = pd.DataFrame(X_test_scaled, columns=X_test.columns)\n",
    "duplicates = pd.concat([X_train_df, X_test_df]).duplicated().sum()\n",
    "print(f\"Filas duplicadas entre train y test: {duplicates}\")\n",
    "\n",
    "# 2. Correlaciones entre caracter칤sticas y variable objetivo\n",
    "correlations = X_train.corrwith(y_train)\n",
    "print(\"\\nCorrelaciones entre caracter칤sticas y 'Energy Consumption':\")\n",
    "print(correlations.sort_values(ascending=False))\n",
    "\n",
    "# 3. Validaci칩n cruzada para XGBoost b치sico\n",
    "cv_scores = cross_val_score(models['XGBoost'], X_train_scaled, y_train, cv=5, scoring='r2')\n",
    "print(f\"\\nValidaci칩n cruzada (5-fold) para XGBoost - R: {cv_scores.mean():.4f} (+/- {cv_scores.std() * 2:.4f})\")\n",
    "\n",
    "# 4. Comparar primeras filas de X_train y X_test\n",
    "print(\"\\nPrimeras 5 filas de X_train:\")\n",
    "print(X_train.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b88fea17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n",
      "Mejores par치metros para XGBoost: OrderedDict({'colsample_bytree': 0.8155553746682142, 'learning_rate': 0.15943036309640915, 'max_depth': 3, 'n_estimators': 200, 'subsample': 0.6})\n",
      "Mejor score CV: 5645.3567\n"
     ]
    }
   ],
   "source": [
    "# 5. OPTIMIZACI칍N CON BAYESIAN SEARCH PARA XGBoost (ejemplo, puedes extender a otros)\n",
    "bayes_search = BayesSearchCV(\n",
    "    XGBRegressor(random_state=42, eval_metric='rmse'),\n",
    "    {\n",
    "        'n_estimators': Integer(50, 200),\n",
    "        'max_depth': Integer(3, 10),\n",
    "        'learning_rate': Real(0.01, 0.3, prior='log-uniform'),\n",
    "        'subsample': Real(0.6, 1.0),\n",
    "        'colsample_bytree': Real(0.6, 1.0)\n",
    "    },\n",
    "    n_iter=30,\n",
    "    cv=3,\n",
    "    scoring='neg_mean_squared_error',\n",
    "    n_jobs=-1,\n",
    "    verbose=1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "bayes_search.fit(X_train_scaled, y_train)\n",
    "print(f\"Mejores par치metros para XGBoost: {bayes_search.best_params_}\")\n",
    "print(f\"Mejor score CV: {-bayes_search.best_score_:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "19c507bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== MODELO OPTIMIZADO (ENTRENAMIENTO) ===\n",
      "MSE: 1246.6236\n",
      "RMSE: 35.3076\n",
      "R: 0.9986\n",
      "MAE: 27.7898\n",
      "\n",
      "=== MODELO OPTIMIZADO (PRUEBA) ===\n",
      "MSE: 1246.6236\n",
      "RMSE: 35.3076\n",
      "R: 0.9986\n",
      "MAE: 27.7898\n",
      "\n",
      "CV RMSE: 67.4988 (+/- 36.0738)\n"
     ]
    }
   ],
   "source": [
    "# 6. MODELO OPTIMIZADO (usamos XGBoost optimizado como ejemplo principal)\n",
    "ensemble_optimized = bayes_search.best_estimator_\n",
    "\n",
    "# Predicciones para entrenamiento y prueba\n",
    "y_pred_train_opt = ensemble_optimized.predict(X_train_scaled)\n",
    "y_pred_test_opt = ensemble_optimized.predict(X_test_scaled)\n",
    "\n",
    "# M칠tricas para entrenamiento\n",
    "mse_train_opt = mean_squared_error(y_train, y_pred_train_opt)\n",
    "rmse_train_opt = np.sqrt(mse_train_opt)\n",
    "r2_train_opt = r2_score(y_train, y_pred_train_opt)\n",
    "mae_train_opt = mean_absolute_error(y_train, y_pred_train_opt)\n",
    "\n",
    "# M칠tricas para prueba\n",
    "mse_test_opt = mean_squared_error(y_test, y_pred_test_opt)\n",
    "rmse_test_opt = np.sqrt(mse_test_opt)\n",
    "r2_test_opt = r2_score(y_test, y_pred_test_opt)\n",
    "mae_test_opt = mean_absolute_error(y_test, y_pred_test_opt)\n",
    "\n",
    "print(f\"\\n=== MODELO OPTIMIZADO (ENTRENAMIENTO) ===\")\n",
    "print(f\"MSE: {mse_train_opt:.4f}\")\n",
    "print(f\"RMSE: {rmse_train_opt:.4f}\")\n",
    "print(f\"R: {r2_train_opt:.4f}\")\n",
    "print(f\"MAE: {mae_train_opt:.4f}\")\n",
    "\n",
    "print(f\"\\n=== MODELO OPTIMIZADO (PRUEBA) ===\")\n",
    "print(f\"MSE: {mse_test_opt:.4f}\")\n",
    "print(f\"RMSE: {rmse_test_opt:.4f}\")\n",
    "print(f\"R: {r2_test_opt:.4f}\")\n",
    "print(f\"MAE: {mae_test_opt:.4f}\")\n",
    "\n",
    "# Validaci칩n cruzada\n",
    "cv_scores = cross_val_score(ensemble_optimized, X_train_scaled, y_train, cv=5, scoring='neg_mean_squared_error')\n",
    "print(f\"\\nCV RMSE: {np.sqrt(-cv_scores.mean()):.4f} (+/- {np.sqrt(cv_scores.std() * 2):.4f})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f4666f21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Predicciones de entrenamiento guardadas en '../data/results/ensemble_predictions_train.csv'\n",
      "Predicciones de prueba guardadas en '../data/results/ensemble_predictions_test.csv'\n"
     ]
    }
   ],
   "source": [
    "# 7. GUARDAR RESULTADOS EN CSV\n",
    "train_results = pd.DataFrame({\n",
    "    'Valores Reales': y_train,\n",
    "    'Predicciones': y_pred_train_opt,\n",
    "    'Diferencia': y_train - y_pred_train_opt\n",
    "})\n",
    "train_results.to_csv('../data/results/ensemble_predictions_train.csv', index=False)\n",
    "print(\"\\nPredicciones de entrenamiento guardadas en '../data/results/ensemble_predictions_train.csv'\")\n",
    "\n",
    "test_results = pd.DataFrame({\n",
    "    'Valores Reales': y_test,\n",
    "    'Predicciones': y_pred_test_opt,\n",
    "    'Diferencia': y_test - y_pred_test_opt\n",
    "})\n",
    "test_results.to_csv('../data/results/ensemble_predictions_test.csv', index=False)\n",
    "print(\"Predicciones de prueba guardadas en '../data/results/ensemble_predictions_test.csv'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "462dd49d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "游늵 Gr치fico de prueba guardado en: ../data/figures/ensemble_comparative_analysis_test.png\n",
      "游늵 Gr치fico de entrenamiento guardado en: ../data/figures/ensemble_comparative_analysis_train.png\n"
     ]
    }
   ],
   "source": [
    "# 8. VISUALIZACIONES\n",
    "output_dir = \"../data/figures/\"\n",
    "\n",
    "# Visualizaciones para el conjunto de prueba (modelo optimizado)\n",
    "fig_test, axes_test = plt.subplots(2, 2, figsize=(15, 12))\n",
    "\n",
    "axes_test[0,0].scatter(y_test, y_pred_test_opt, alpha=0.6)\n",
    "axes_test[0,0].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "axes_test[0,0].set_xlabel('Valores Reales')\n",
    "axes_test[0,0].set_ylabel('Predicciones')\n",
    "axes_test[0,0].set_title(f'Ensemble Optimizado (Prueba) - R = {r2_test_opt:.4f}')\n",
    "axes_test[0,0].grid(True, alpha=0.3)\n",
    "\n",
    "residuos_test = y_test - y_pred_test_opt\n",
    "axes_test[0,1].scatter(y_pred_test_opt, residuos_test, alpha=0.6)\n",
    "axes_test[0,1].axhline(y=0, color='r', linestyle='--')\n",
    "axes_test[0,1].set_xlabel('Predicciones')\n",
    "axes_test[0,1].set_ylabel('Residuos')\n",
    "axes_test[0,1].set_title('Gr치fico de Residuos (Prueba)')\n",
    "axes_test[0,1].grid(True, alpha=0.3)\n",
    "\n",
    "# Comparaci칩n de modelos (MSE y R)\n",
    "model_names = list(results.keys())\n",
    "mse_values = [results[m]['MSE'] for m in model_names]\n",
    "r2_values = [results[m]['R'] for m in model_names]\n",
    "\n",
    "x_pos = np.arange(len(model_names))\n",
    "axes_test[1,0].bar(x_pos, mse_values, alpha=0.7)\n",
    "axes_test[1,0].set_xlabel('Modelo')\n",
    "axes_test[1,0].set_ylabel('MSE')\n",
    "axes_test[1,0].set_title('Comparaci칩n MSE por Modelo')\n",
    "axes_test[1,0].set_xticks(x_pos)\n",
    "axes_test[1,0].set_xticklabels(model_names, rotation=45)\n",
    "\n",
    "axes_test[1,1].bar(x_pos, r2_values, alpha=0.7, color='green')\n",
    "axes_test[1,1].set_xlabel('Modelo')\n",
    "axes_test[1,1].set_ylabel('R')\n",
    "axes_test[1,1].set_title('Comparaci칩n R por Modelo')\n",
    "axes_test[1,1].set_xticks(x_pos)\n",
    "axes_test[1,1].set_xticklabels(model_names, rotation=45)\n",
    "\n",
    "plt.tight_layout()\n",
    "fig_test.savefig(f\"{output_dir}ensemble_comparative_analysis_test.png\", dpi=300, bbox_inches='tight')\n",
    "plt.close(fig_test)\n",
    "print(f\"游늵 Gr치fico de prueba guardado en: {output_dir}ensemble_comparative_analysis_test.png\")\n",
    "\n",
    "# Visualizaciones para el conjunto de entrenamiento\n",
    "fig_train, axes_train = plt.subplots(1, 2, figsize=(15, 6))\n",
    "\n",
    "axes_train[0].scatter(y_train, y_pred_train_opt, alpha=0.6)\n",
    "axes_train[0].plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], 'r--', lw=2)\n",
    "axes_train[0].set_xlabel('Valores Reales')\n",
    "axes_train[0].set_ylabel('Predicciones')\n",
    "axes_train[0].set_title(f'Ensemble Optimizado (Entrenamiento) - R = {r2_train_opt:.4f}')\n",
    "axes_train[0].grid(True, alpha=0.3)\n",
    "\n",
    "residuos_train = y_train - y_pred_train_opt\n",
    "axes_train[1].scatter(y_pred_train_opt, residuos_train, alpha=0.6)\n",
    "axes_train[1].axhline(y=0, color='r', linestyle='--')\n",
    "axes_train[1].set_xlabel('Predicciones')\n",
    "axes_train[1].set_ylabel('Residuos')\n",
    "axes_train[1].set_title('Gr치fico de Residuos (Entrenamiento)')\n",
    "axes_train[1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "fig_train.savefig(f\"{output_dir}ensemble_comparative_analysis_train.png\", dpi=300, bbox_inches='tight')\n",
    "plt.close(fig_train)\n",
    "print(f\"游늵 Gr치fico de entrenamiento guardado en: {output_dir}ensemble_comparative_analysis_train.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "da75ce8d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== RESUMEN DE RESULTADOS ===\n",
      "                              Modelo        MSE     RMSE      R      MAE\n",
      "Random Forest          Random Forest  2097.7550  45.8013  0.9976  36.0567\n",
      "Gradient Boosting  Gradient Boosting  2536.2069  50.3608  0.9971  39.1547\n",
      "XGBoost                      XGBoost    29.4600   5.4277  1.0000   3.8408\n"
     ]
    }
   ],
   "source": [
    "# 9. TABLA RESUMEN DE RESULTADOS\n",
    "print(\"\\n=== RESUMEN DE RESULTADOS ===\")\n",
    "resumen = pd.DataFrame(results).T\n",
    "resumen['Modelo'] = resumen.index\n",
    "resumen = resumen[['Modelo', 'MSE', 'RMSE', 'R', 'MAE']]\n",
    "print(resumen.round(4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "29ffc767",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Modelo y scaler guardados como 'ensemble_model.pkl' y 'ensemble_scaler.pkl'\n"
     ]
    }
   ],
   "source": [
    "# 10. GUARDAR EL MODELO\n",
    "joblib.dump(ensemble_optimized, '../data/results/ensemble_model.pkl')\n",
    "joblib.dump(scaler, '../data/results/ensemble_scaler.pkl')\n",
    "print(\"\\nModelo y scaler guardados como 'ensemble_model.pkl' y 'ensemble_scaler.pkl'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ba924d3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "춰Modelos ensemble implementados exitosamente!\n"
     ]
    }
   ],
   "source": [
    "# 11. FUNCI칍N PARA NUEVAS PREDICCIONES\n",
    "def predecir_nuevos_datos(nuevos_datos, modelo=ensemble_optimized, escalador=scaler):\n",
    "    \"\"\"\n",
    "    Funci칩n para hacer predicciones en nuevos datos\n",
    "\n",
    "    Parameters:\n",
    "    nuevos_datos: array-like o DataFrame, datos a predecir\n",
    "    modelo: modelo ensemble entrenado\n",
    "    escalador: StandardScaler ajustado\n",
    "\n",
    "    Returns:\n",
    "    predicciones: array con las predicciones\n",
    "    \"\"\"\n",
    "    if isinstance(nuevos_datos, pd.DataFrame):\n",
    "        nuevos_datos = nuevos_datos.values\n",
    "    datos_escalados = escalador.transform(nuevos_datos)\n",
    "    predicciones = modelo.predict(datos_escalados)\n",
    "    return predicciones\n",
    "\n",
    "print(\"\\n춰Modelos ensemble implementados exitosamente!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
